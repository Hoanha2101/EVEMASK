{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-metric-learning -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda import amp\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28192ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (224, 224)\n",
    "data_transform = A.Compose([A.Resize(INPUT_SIZE[0], INPUT_SIZE[1]),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.VerticalFlip(p=0.5),\n",
    "                        A.Rotate(limit=45, p=1.0),\n",
    "                        A.CoarseDropout(\n",
    "                                    max_holes=8,                \n",
    "                                    max_height=16,              \n",
    "                                    max_width=16,               \n",
    "                                    min_holes=1,                \n",
    "                                    min_height=8,               \n",
    "                                    min_width=8,                \n",
    "                                    fill_value=0,               \n",
    "                                    p=0.5                        \n",
    "                                ),\n",
    "                        A.RandomBrightnessContrast(\n",
    "                                brightness_limit=(-0.1,0.1), \n",
    "                                contrast_limit=(-0.1, 0.1), \n",
    "                                p=0.5),\n",
    "                        A.Normalize(\n",
    "                                mean=[0.485, 0.456, 0.406], \n",
    "                                std=[0.229, 0.224, 0.225], \n",
    "                                max_pixel_value=255.0, \n",
    "                                p=1.0),\n",
    "                        ToTensorV2()], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DATA(Dataset):\n",
    "    def __init__(self, path, transform=None, phase=\"train\"):\n",
    "        self.path = path\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        \n",
    "        folders = os.listdir(path)\n",
    "        self.image_paths = []  # ❌ Chỉ lưu đường dẫn, không load ảnh\n",
    "        self.labels = []\n",
    "        \n",
    "        self.label_dict = {}\n",
    "        for i, value in enumerate(folders):\n",
    "            self.label_dict[value] = i\n",
    "        print(self.label_dict)\n",
    "        \n",
    "        for image_folder in folders:\n",
    "            items_path = os.path.join(self.path, image_folder)\n",
    "            items_list = os.listdir(items_path)\n",
    "            \n",
    "            for image_name in items_list:\n",
    "                image_path = os.path.join(items_path, image_name)\n",
    "                self.image_paths.append(image_path)  # ✅ Chỉ lưu path\n",
    "                self.labels.append(self.label_dict[image_folder])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ✅ Load ảnh khi cần thiết\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.phase == \"train\":\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)[\"image\"]\n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)[\"image\"]\n",
    "            return image, torch.tensor(label, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "train_path = \"/kaggle/input/data-augmented-model-2/augmented_data_model_2\"\n",
    "train_data =  DATA(train_path, data_transform, phase = \"train\")\n",
    "end = time.time()\n",
    "print(f\"Load time: {round(end - start, 4)} s\")\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_img, label = train_data[100] # image at index = 100\n",
    "img_np = anchor_img.numpy()\n",
    "img_np = np.transpose(img_np, (1,2,0))\n",
    "\n",
    "plt.imshow(img_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4529742",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  32 # Batch = 32 là max khi train với colab và kaggle, nếu lớn hơn thì out of memory -- Vram có 16gb thôi\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers = os.cpu_count()\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Supervised Contrastive Loss implementation - Improved version\n",
    "    Ref: https://arxiv.org/abs/2004.11362\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.1, base_temperature=0.07):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, feature_dim]\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        \n",
    "        # Ensure labels are correct type\n",
    "        labels = labels.long().view(-1)\n",
    "        \n",
    "        if len(features.shape) < 3:\n",
    "            features = features.unsqueeze(1)\n",
    "            \n",
    "        # Normalize features\n",
    "        features = F.normalize(features, p=2, dim=2)\n",
    "        \n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        \n",
    "        anchor_feature = contrast_feature\n",
    "        anchor_count = contrast_count\n",
    "        \n",
    "        # Compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        \n",
    "        # For numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        \n",
    "        # Create label mask\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        if labels.shape[0] != batch_size:\n",
    "            raise ValueError('Num of labels does not match num of features')\n",
    "            \n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        \n",
    "        # Mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "        \n",
    "        # Compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        # Compute mean of log-likelihood over positive\n",
    "        # Only compute loss for samples that have positive pairs\n",
    "        valid_samples = mask.sum(1) > 0\n",
    "        if valid_samples.sum() == 0:\n",
    "            return torch.tensor(0.0, requires_grad=True).to(device)\n",
    "            \n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
    "        \n",
    "        # Loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos[valid_samples]\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, emb_dim=128):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        base_model = models.resnet18(pretrained=True)  \n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])  \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(256, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)           # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)        # [B, 512]\n",
    "        x = self.fc(x)                 # [B, emb_dim]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(256).to(device)\n",
    "x = torch.rand([32, 3, 224, 224]).to(device) # input random\n",
    "output = model(x)\n",
    "print(output.shape) # output is torch.Size([32, 256]) -> good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e618f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 256 #\n",
    "model = Network(embedding_dims).to(device)\n",
    "criterion = SupervisedContrastiveLoss(temperature=0.1).to(device) \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "def TEST(folder_path, model, transforms, key):\n",
    "\n",
    "    label_org = []\n",
    "    dir_org = []\n",
    "    label_test = []\n",
    "    dir_test_path = []\n",
    "    dir_org_path = []\n",
    "    REFER_DICT = {}\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over each subfolder in the folder_path\n",
    "        for label_index, subfolder_name in enumerate(os.listdir(folder_path)):\n",
    "            REFER_DICT[label_index] = subfolder_name\n",
    "            subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "            image_files = os.listdir(subfolder_path)\n",
    "            for image_index, image_file in enumerate(image_files):\n",
    "\n",
    "                image_path = os.path.join(subfolder_path, image_file)\n",
    "\n",
    "                if key in image_path:\n",
    "\n",
    "                    image = Image.open(image_path).convert('RGB')\n",
    "                    image = transforms(image=np.array(image))[\"image\"]\n",
    "                    # Extract the embedding for the first image in the folder\n",
    "                    embedding = model(image.unsqueeze(0).to(\"cuda\"))\n",
    "                    dir_org.append(embedding)\n",
    "                    label_org.append(label_index)\n",
    "                    dir_org_path.append(image_path)\n",
    "                else:\n",
    "                    # Store the path and label for other images\n",
    "                    dir_test_path.append(image_path)\n",
    "                    label_test.append(label_index)\n",
    "\n",
    "        predict_label = []\n",
    "        Max_sim = []\n",
    "\n",
    "        if not dir_org:  # Nếu không có ảnh reference\n",
    "            print(f\"Warning: No reference images found with key '{key}'\")\n",
    "            return 0.0\n",
    "\n",
    "        # Iterate over test images\n",
    "        for test_image_path in dir_test_path:\n",
    "\n",
    "            test_image = Image.open(test_image_path).convert('RGB')\n",
    "            test_image = transforms(image=np.array(test_image))[\"image\"]\n",
    "\n",
    "            # Extract the embedding for the test image\n",
    "            test_embedding = model(test_image.unsqueeze(0).to(\"cuda\"))\n",
    "            similarities = []\n",
    "\n",
    "            # Calculate cosine similarity with each original embedding\n",
    "            for org_embedding in dir_org:\n",
    "\n",
    "                cosine_sim = cosine_similarity(org_embedding.cpu().detach().numpy(), test_embedding.cpu().detach().numpy())\n",
    "                similarities.append(cosine_sim[0][0])\n",
    "\n",
    "            if similarities:\n",
    "                Max_sim.append(max(similarities))\n",
    "                max_similarity_index = np.argmax(similarities)\n",
    "                predict_label.append(label_org[max_similarity_index])\n",
    "            else:\n",
    "                print(f\"Warning: No similarities calculated for {test_image_path}\")\n",
    "                predict_label.append(-1)  # Hoặc một giá trị mặc định\n",
    "        if not predict_label or not label_test:\n",
    "            print(\"Warning: No predictions or labels to evaluate\")\n",
    "            return 0.0\n",
    "                \n",
    "        accuracy = accuracy_score(predict_label, label_test)\n",
    "        print(f'----Key: {key}')\n",
    "        print(f'----Number of test images: {len(label_test)}')\n",
    "        print(f'----Number of reference images: {len(label_org)}')\n",
    "        print(f'----Accuracy: {accuracy:.4f}')\n",
    "        print()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "preprocess = A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e39270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import signal\n",
    "import sys\n",
    "\n",
    "# Khởi tạo lists để lưu training history\n",
    "train_history = {\n",
    "    'epoch': [],\n",
    "    'loss': [],\n",
    "    'accuracy': [],\n",
    "    'learning_rate': [],\n",
    "    'timestamp': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_results():\n",
    "    os.makedirs('/kaggle/working/outputs', exist_ok=True)\n",
    "    \n",
    "    # Save training history\n",
    "    df_history = pd.DataFrame(train_history)\n",
    "    df_history.to_csv('/kaggle/working/outputs/training_history.csv', index=False)\n",
    "    \n",
    "    # Save final model\n",
    "    final_model_path = f\"/kaggle/working/outputs/final_model_epoch_{epochs}.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'final_accuracy': ACC,\n",
    "        'training_history': train_history\n",
    "    }, final_model_path)\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'total_epochs': epochs,\n",
    "        'best_accuracy': float(ACC),\n",
    "        'final_loss': float(train_history['loss'][-1]) if train_history['loss'] else 0.0,\n",
    "        'best_model_path': best_model_path,\n",
    "        'final_model_path': final_model_path,\n",
    "        'training_completed': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_samples': len(train_data),\n",
    "        'batch_size': batch_size,\n",
    "        'embedding_dims': embedding_dims\n",
    "    }\n",
    "    \n",
    "    with open('/kaggle/working/outputs/training_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    results_df = pd.DataFrame([summary])\n",
    "    results_df.to_csv('/kaggle/working/outputs/final_results.csv', index=False)\n",
    "    \n",
    "    print(f\"✅ Results saved! Best Accuracy: {ACC:.4f}\")\n",
    "\n",
    "# Signal handler\n",
    "def signal_handler(sig, frame):\n",
    "    print('\\nTraining interrupted! Saving current progress...')\n",
    "    save_final_results()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "model.train()\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "ACC = 0\n",
    "best_model_path = None\n",
    "\n",
    "# ✅ Sửa lỗi typo đường dẫn\n",
    "os.makedirs('/kaggle/working/outputs', exist_ok=True)\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    running_loss = []\n",
    "\n",
    "    for step, (anchor_img, label) in enumerate(train_loader):\n",
    "        anchor_img = anchor_img.to(device).float()\n",
    "        label = label.to(device).long()\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=True):\n",
    "            outputs = model(anchor_img)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss = loss / 4\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % 4 == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "            if (step + 1) % 20 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    epoch_loss = np.mean(running_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        test_path = \"/kaggle/input/logo-verify-test/logo_verify_test\"\n",
    "        accuracy = TEST(test_path, model, preprocess, key=\"000000\")\n",
    "        model.train()\n",
    "        \n",
    "        if accuracy >= ACC:\n",
    "            if best_model_path and os.path.exists(best_model_path):\n",
    "                os.remove(best_model_path)\n",
    "            \n",
    "            # ✅ Đảm bảo thư mục tồn tại\n",
    "            os.makedirs('/kaggle/working/outputs', exist_ok=True)\n",
    "            best_model_path = f\"/kaggle/working/outputs/model_best_epoch_{epoch+1}_acc_{accuracy:.4f}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'accuracy': accuracy,\n",
    "                'loss': epoch_loss\n",
    "            }, best_model_path)\n",
    "            ACC = accuracy\n",
    "    else:\n",
    "        accuracy = None\n",
    "    \n",
    "    # Lưu training history\n",
    "    train_history['epoch'].append(epoch + 1)\n",
    "    train_history['loss'].append(float(epoch_loss))\n",
    "    train_history['accuracy'].append(float(accuracy) if accuracy is not None else None)\n",
    "    train_history['learning_rate'].append(float(current_lr))\n",
    "    train_history['timestamp'].append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    print(\"Epoch: {}/{} - Loss: {:.4f} - LR: {:.2e}{}\".format(\n",
    "        epoch+1, epochs, epoch_loss, current_lr,\n",
    "        f\" - Accuracy: {accuracy:.4f}\" if accuracy is not None else \"\"\n",
    "    ))\n",
    "    \n",
    "    # ✅ Đảm bảo thư mục tồn tại trước mỗi lần lưu\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        os.makedirs('/kaggle/working/outputs', exist_ok=True)\n",
    "        df_history = pd.DataFrame(train_history)\n",
    "        df_history.to_csv('/kaggle/working/outputs/training_history.csv', index=False)\n",
    "        print(f\"Training history saved at epoch {epoch+1}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*50)\n",
    "save_final_results()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
