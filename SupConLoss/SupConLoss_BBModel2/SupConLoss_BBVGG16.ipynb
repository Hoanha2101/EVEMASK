{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed888c52",
   "metadata": {},
   "source": [
    "# Cài đặt thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6f9748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DELL\\miniconda3\\envs\\faceid\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning -q\n",
    "!pip install matplotlib -q\n",
    "!pip install tqdm -q\n",
    "!pip install albumentations -q\n",
    "!pip install timm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97ed5ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.9 from \"c:\\Users\\DELL\\miniconda3\\envs\\faceid\\python.exe\"\n  * The NumPy version is: \"1.23.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\numpy\\_core\\__init__.py:23\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\numpy\\_core\\multiarray.py:10\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\numpy\\_core\\overrides.py:8\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[0;32m     12\u001b[0m ARRAY_FUNCTIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\numpy\\_core\\__init__.py:49\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m], sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m1\u001b[39m], sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[0;32m     48\u001b[0m         __version__, exc)\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m envkey \u001b[38;5;129;01min\u001b[39;00m env_added:\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.9 from \"c:\\Users\\DELL\\miniconda3\\envs\\faceid\\python.exe\"\n  * The NumPy version is: \"1.23.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy._core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\matplotlib\\__init__.py:159\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\matplotlib\\colors.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\matplotlib\\ticker.py:144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    146\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    148\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    157\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\miniconda3\\envs\\faceid\\lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda import amp\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b034c1",
   "metadata": {},
   "source": [
    "# Setup Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b65b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e71a2f",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (224, 224)\n",
    "data_transform = A.Compose([A.Resize(INPUT_SIZE[0], INPUT_SIZE[1]),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.VerticalFlip(p=0.5),\n",
    "                        A.Rotate(limit=45, p=1.0),\n",
    "                        A.CoarseDropout(\n",
    "                                    max_holes=8,                \n",
    "                                    max_height=16,              \n",
    "                                    max_width=16,               \n",
    "                                    min_holes=1,                \n",
    "                                    min_height=8,               \n",
    "                                    min_width=8,                \n",
    "                                    fill_value=0,               \n",
    "                                    p=0.5                        \n",
    "                                ),\n",
    "                        A.RandomBrightnessContrast(\n",
    "                                brightness_limit=(-0.1,0.1), \n",
    "                                contrast_limit=(-0.1, 0.1), \n",
    "                                p=0.5),\n",
    "                        A.Normalize(\n",
    "                                mean=[0.485, 0.456, 0.406], \n",
    "                                std=[0.229, 0.224, 0.225], \n",
    "                                max_pixel_value=255.0, \n",
    "                                p=1.0),\n",
    "                        ToTensorV2()], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f260f4",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09caa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA(Dataset):\n",
    "    def __init__(self, path, transform=None, phase=\"train\"):\n",
    "        self.path = path\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        \n",
    "        folders = os.listdir(path)\n",
    "        self.image_paths = []  # ❌ Chỉ lưu đường dẫn, không load ảnh\n",
    "        self.labels = []\n",
    "        \n",
    "        self.label_dict = {}\n",
    "        for i, value in enumerate(folders):\n",
    "            self.label_dict[value] = i\n",
    "        print(self.label_dict)\n",
    "        \n",
    "        for image_folder in folders:\n",
    "            items_path = os.path.join(self.path, image_folder)\n",
    "            items_list = os.listdir(items_path)\n",
    "            \n",
    "            for image_name in items_list:\n",
    "                image_path = os.path.join(items_path, image_name)\n",
    "                self.image_paths.append(image_path)  # ✅ Chỉ lưu path\n",
    "                self.labels.append(self.label_dict[image_folder])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ✅ Load ảnh khi cần thiết\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.phase == \"train\":\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)[\"image\"]\n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)[\"image\"]\n",
    "            return image, torch.tensor(label, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19359f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "train_path = \"/kaggle/input/data-augmented-model-2/augmented_data_model_2\"\n",
    "train_data =  DATA(train_path, data_transform, phase = \"train\")\n",
    "end = time.time()\n",
    "print(f\"Load time: {round(end - start, 4)} s\")\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c626682",
   "metadata": {},
   "source": [
    "# Show and Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086177ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_img, label = train_data[100] # image at index = 100\n",
    "img_np = anchor_img.numpy()\n",
    "img_np = np.transpose(img_np, (1,2,0))\n",
    "\n",
    "plt.imshow(img_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  32 # Batch = 32 là max khi train với colab và kaggle, nếu lớn hơn thì out of memory -- Vram có 16gb thôi\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers = os.cpu_count()\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c63e9a",
   "metadata": {},
   "source": [
    "# SupCon Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Supervised Contrastive Loss implementation - Improved version\n",
    "    Ref: https://arxiv.org/abs/2004.11362\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.1, base_temperature=0.07):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, feature_dim]\n",
    "            labels: ground truth of shape [bsz].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        \n",
    "        # Ensure labels are correct type\n",
    "        labels = labels.long().view(-1)\n",
    "        \n",
    "        if len(features.shape) < 3:\n",
    "            features = features.unsqueeze(1)\n",
    "            \n",
    "        # Normalize features\n",
    "        features = F.normalize(features, p=2, dim=2)\n",
    "        \n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        \n",
    "        anchor_feature = contrast_feature\n",
    "        anchor_count = contrast_count\n",
    "        \n",
    "        # Compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        \n",
    "        # For numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        \n",
    "        # Create label mask\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        if labels.shape[0] != batch_size:\n",
    "            raise ValueError('Num of labels does not match num of features')\n",
    "            \n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        \n",
    "        # Mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "        \n",
    "        # Compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        # Compute mean of log-likelihood over positive\n",
    "        # Only compute loss for samples that have positive pairs\n",
    "        valid_samples = mask.sum(1) > 0\n",
    "        if valid_samples.sum() == 0:\n",
    "            return torch.tensor(0.0, requires_grad=True).to(device)\n",
    "            \n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
    "        \n",
    "        # Loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos[valid_samples]\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a44530",
   "metadata": {},
   "source": [
    "# BackBone VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c68dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = models.vgg16(pretrained=True)\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, emb_dim=128):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv = model_.features\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 512),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(512, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c9155",
   "metadata": {},
   "source": [
    "# Test Model ForWard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd340ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(256).to(device)\n",
    "x = torch.rand([32, 3, 224, 224]).to(device) # input random\n",
    "output = model(x)\n",
    "print(output.shape) # output is torch.Size([32, 256]) -> good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f9002",
   "metadata": {},
   "source": [
    "# SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29736d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 256 #\n",
    "model = Network(embedding_dims).to(device)\n",
    "criterion = SupervisedContrastiveLoss(temperature=0.1).to(device) \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8fdeb4",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f51f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "def TEST(folder_path, model, transforms, key):\n",
    "\n",
    "    label_org = []\n",
    "    dir_org = []\n",
    "    label_test = []\n",
    "    dir_test_path = []\n",
    "    dir_org_path = []\n",
    "    REFER_DICT = {}\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over each subfolder in the folder_path\n",
    "        for label_index, subfolder_name in enumerate(os.listdir(folder_path)):\n",
    "            REFER_DICT[label_index] = subfolder_name\n",
    "            subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "            image_files = os.listdir(subfolder_path)\n",
    "            for image_index, image_file in enumerate(image_files):\n",
    "\n",
    "                image_path = os.path.join(subfolder_path, image_file)\n",
    "\n",
    "                if key in image_path:\n",
    "\n",
    "                    image = Image.open(image_path).convert('RGB')\n",
    "                    image = transforms(image=np.array(image))[\"image\"]\n",
    "                    # Extract the embedding for the first image in the folder\n",
    "                    embedding = model(image.unsqueeze(0).to(\"cuda\"))\n",
    "                    dir_org.append(embedding)\n",
    "                    label_org.append(label_index)\n",
    "                    dir_org_path.append(image_path)\n",
    "                else:\n",
    "                    # Store the path and label for other images\n",
    "                    dir_test_path.append(image_path)\n",
    "                    label_test.append(label_index)\n",
    "\n",
    "        predict_label = []\n",
    "        Max_sim = []\n",
    "\n",
    "        if not dir_org:  # Nếu không có ảnh reference\n",
    "            print(f\"Warning: No reference images found with key '{key}'\")\n",
    "            return 0.0\n",
    "\n",
    "        # Iterate over test images\n",
    "        for test_image_path in dir_test_path:\n",
    "\n",
    "            test_image = Image.open(test_image_path).convert('RGB')\n",
    "            test_image = transforms(image=np.array(test_image))[\"image\"]\n",
    "\n",
    "            # Extract the embedding for the test image\n",
    "            test_embedding = model(test_image.unsqueeze(0).to(\"cuda\"))\n",
    "            similarities = []\n",
    "\n",
    "            # Calculate cosine similarity with each original embedding\n",
    "            for org_embedding in dir_org:\n",
    "\n",
    "                cosine_sim = cosine_similarity(org_embedding.cpu().detach().numpy(), test_embedding.cpu().detach().numpy())\n",
    "                similarities.append(cosine_sim[0][0])\n",
    "\n",
    "            if similarities:\n",
    "                Max_sim.append(max(similarities))\n",
    "                max_similarity_index = np.argmax(similarities)\n",
    "                predict_label.append(label_org[max_similarity_index])\n",
    "            else:\n",
    "                print(f\"Warning: No similarities calculated for {test_image_path}\")\n",
    "                predict_label.append(-1)  # Hoặc một giá trị mặc định\n",
    "        if not predict_label or not label_test:\n",
    "            print(\"Warning: No predictions or labels to evaluate\")\n",
    "            return 0.0\n",
    "                \n",
    "        accuracy = accuracy_score(predict_label, label_test)\n",
    "        print(f'----Key: {key}')\n",
    "        print(f'----Number of test images: {len(label_test)}')\n",
    "        print(f'----Number of reference images: {len(label_org)}')\n",
    "        print(f'----Accuracy: {accuracy:.4f}')\n",
    "        print()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "preprocess = A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26181a8",
   "metadata": {},
   "source": [
    "# Tracking and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import signal\n",
    "import sys\n",
    "\n",
    "# Khởi tạo lists để lưu training history\n",
    "train_history = {\n",
    "    'epoch': [],\n",
    "    'loss': [],\n",
    "    'accuracy': [],\n",
    "    'learning_rate': [],\n",
    "    'timestamp': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_results():\n",
    "    os.makedirs('/kaggle/working/outputs', exist_ok=True)\n",
    "    \n",
    "    # Save training history\n",
    "    df_history = pd.DataFrame(train_history)\n",
    "    df_history.to_csv('/kaggle/working/outputs/training_history.csv', index=False)\n",
    "    \n",
    "    # Save final model\n",
    "    final_model_path = f\"/kaggle/working/outputs/final_model_epoch_{epochs}.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'final_accuracy': ACC,\n",
    "        'training_history': train_history\n",
    "    }, final_model_path)\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'total_epochs': epochs,\n",
    "        'best_accuracy': float(ACC),\n",
    "        'final_loss': float(train_history['loss'][-1]) if train_history['loss'] else 0.0,\n",
    "        'best_model_path': best_model_path,\n",
    "        'final_model_path': final_model_path,\n",
    "        'training_completed': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_samples': len(train_data),\n",
    "        'batch_size': batch_size,\n",
    "        'embedding_dims': embedding_dims\n",
    "    }\n",
    "    \n",
    "    with open('/kaggle/working/outputs/training_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    results_df = pd.DataFrame([summary])\n",
    "    results_df.to_csv('/kaggle/working/outputs/final_results.csv', index=False)\n",
    "    \n",
    "    print(f\"✅ Results saved! Best Accuracy: {ACC:.4f}\")\n",
    "\n",
    "# Signal handler\n",
    "def signal_handler(sig, frame):\n",
    "    print('\\nTraining interrupted! Saving current progress...')\n",
    "    save_final_results()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf39b60",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d939efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "model.train()\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "ACC = 0\n",
    "best_model_path = None\n",
    "\n",
    "os.makedirs('/kaggle/working?outputs', exist_ok=True)  # Đảm bảo thư mục tồn tại\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    running_loss = []\n",
    "\n",
    "    for step, (anchor_img, label) in enumerate(train_loader):\n",
    "        anchor_img = anchor_img.to(device).float()\n",
    "        label = label.to(device).long()  # ❌ Sửa: Đảm bảo label là long type\n",
    "\n",
    "        with torch.amp.autocast('cuda',enabled=True):\n",
    "            outputs = model(anchor_img)\n",
    "            loss = criterion(outputs, label)\n",
    "            loss = loss / 4\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % 4 == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()      \n",
    "\n",
    "            # Memory cleanup mỗi 20 steps\n",
    "            if (step + 1) % 20 == 0:\n",
    "                torch.cuda.empty_cache()    \n",
    "\n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    epoch_loss = np.mean(running_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        test_path = \"/kaggle/input/test-set-seg-extract/TEST_SET\"\n",
    "        accuracy = TEST(test_path, model, preprocess, key=\"000000\")\n",
    "        model.train()\n",
    "        \n",
    "        if accuracy >= ACC:\n",
    "            # Xóa model cũ nếu có\n",
    "            if best_model_path and os.path.exists(best_model_path):\n",
    "                os.remove(best_model_path)\n",
    "            \n",
    "            # Lưu model mới\n",
    "            best_model_path = f\"/kaggle/working/outputs/model_best_epoch_{epoch+1}_acc_{accuracy:.4f}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'accuracy': accuracy,\n",
    "                'loss': epoch_loss\n",
    "            }, best_model_path)\n",
    "            ACC = accuracy\n",
    "    else:\n",
    "        accuracy = None\n",
    "    \n",
    "    # Lưu training history\n",
    "    train_history['epoch'].append(epoch + 1)\n",
    "    train_history['loss'].append(float(epoch_loss))\n",
    "    train_history['accuracy'].append(float(accuracy) if accuracy is not None else None)\n",
    "    train_history['learning_rate'].append(float(current_lr))\n",
    "    train_history['timestamp'].append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    print(\"Epoch: {}/{} - Loss: {:.4f} - LR: {:.2e}{}\".format(\n",
    "        epoch+1, epochs, epoch_loss, current_lr,\n",
    "        f\" - Accuracy: {accuracy:.4f}\" if accuracy is not None else \"\"\n",
    "    ))\n",
    "    \n",
    "    # Lưu CSV mỗi 5 epochs để tránh mất dữ liệu\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        df_history = pd.DataFrame(train_history)\n",
    "        df_history.to_csv('/kaggle/working/outputs/training_history.csv', index=False)\n",
    "        print(f\"Training history saved at epoch {epoch+1}\")\n",
    "\n",
    "# Lưu kết quả cuối cùng\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4deaa",
   "metadata": {},
   "source": [
    "# Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710035fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_final_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faceid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
